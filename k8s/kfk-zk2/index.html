<!doctype html>
<html lang="en-us">
  <head>
    <title> // My New Hugo Site</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.56.0-DEV" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://scylhy.github.io/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="在k8s上搭建kfk-zk集群(2) 这篇接zk的部署方式，整体结构是一样的，包括StorageClass、PV、HeadlessService、StatefulSet，不同的是kfk本身的配置，k8s官方没有k8s的部署教程，我在网上找到一个在k8s上部署kfk的帖子，借用其kfk的模版。
StorageClass我们已经创建，直接使用local-class。
root@hw1:~/zk# kubectl get storageclass NAME PROVISIONER AGE local-class kubernetes.io/no-provisioner 18h  上次仅仅创建了三个PVs,不够用，这里我们为kfk也创建三个PVs，kubectl create -f pv-kfk.yaml。
kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-1 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data11&quot; --- kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-2 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data22&quot; --- kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-3 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data33&quot;  kfk模板借用Kafka on Kubernetes Deploy a highly available Kafka cluster on Kubernetes."/>

    <meta property="og:title" content="" />
<meta property="og:description" content="在k8s上搭建kfk-zk集群(2) 这篇接zk的部署方式，整体结构是一样的，包括StorageClass、PV、HeadlessService、StatefulSet，不同的是kfk本身的配置，k8s官方没有k8s的部署教程，我在网上找到一个在k8s上部署kfk的帖子，借用其kfk的模版。
StorageClass我们已经创建，直接使用local-class。
root@hw1:~/zk# kubectl get storageclass NAME PROVISIONER AGE local-class kubernetes.io/no-provisioner 18h  上次仅仅创建了三个PVs,不够用，这里我们为kfk也创建三个PVs，kubectl create -f pv-kfk.yaml。
kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-1 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data11&quot; --- kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-2 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data22&quot; --- kind: PersistentVolume apiVersion: v1 metadata: name: datadir-kfk-3 labels: type: local spec: storageClassName: local-class capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &quot;/mnt/data33&quot;  kfk模板借用Kafka on Kubernetes Deploy a highly available Kafka cluster on Kubernetes." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://scylhy.github.io/k8s/kfk-zk2/" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://scylhy.github.io"><img class="app-header-avatar" src="/avatar.jpg" alt="John Doe" /></a>
      <h1>My New Hugo Site</h1>
      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc vehicula turpis sit amet elit pretium.</p>
      <div class="app-header-social">
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title"></h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jan 1, 0001
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div></div>
    </header>
    <div class="post-content">
      

<h3 id="在k8s上搭建kfk-zk集群-2">在k8s上搭建kfk-zk集群(2)</h3>

<p>这篇接zk的部署方式，整体结构是一样的，包括StorageClass、PV、HeadlessService、StatefulSet，不同的是kfk本身的配置，k8s官方没有k8s的部署教程，我在网上找到一个在k8s上部署kfk的帖子，借用其kfk的模版。</p>

<p>StorageClass我们已经创建，直接使用local-class。</p>

<pre><code class="language-bash">root@hw1:~/zk# kubectl get storageclass
NAME          PROVISIONER                    AGE
local-class   kubernetes.io/no-provisioner   18h
</code></pre>

<p>上次仅仅创建了三个PVs,不够用，这里我们为kfk也创建三个PVs，<code>kubectl create -f pv-kfk.yaml</code>。</p>

<pre><code class="language-yaml">kind: PersistentVolume
apiVersion: v1
metadata:
  name: datadir-kfk-1
  labels:
    type: local
spec:
  storageClassName: local-class
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/mnt/data11&quot;
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: datadir-kfk-2
  labels:
    type: local
spec:
  storageClassName: local-class
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/mnt/data22&quot;
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: datadir-kfk-3
  labels:
    type: local
spec:
  storageClassName: local-class
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/mnt/data33&quot;
</code></pre>

<p>kfk模板借用<a href="https://imti.co/kafka-kubernetes/#kafka-service">Kafka on Kubernetes Deploy a highly available Kafka cluster on Kubernetes.</a>中kfk部分，修改kfk的spec.volumeClaimTemplates.spec.storageClassName为之前的local-class,以及kfk连接zk的参数 KAFKA_ZOOKEEPER_CONNECT为zk-cs:2181。</p>

<pre><code class="language-kubectl">
</code></pre>

<p>yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
spec:
  ports:
  - name: broker
    port: 9092
    protocol: TCP
    targetPort: kafka
  selector:
    app: kafka
  sessionAffinity: None</p>

<h2 id="type-clusterip">type: ClusterIP</h2>

<p>apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
spec:
  clusterIP: None
  ports:
  - name: broker
    port: 9092
    protocol: TCP
    targetPort: 9092
  selector:
    app: kafka
  sessionAffinity: None</p>

<h2 id="type-clusterip-1">type: ClusterIP</h2>

<p>apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: kafka
  name: kafka
spec:
  podManagementPolicy: OrderedReady
  replicas: 3
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      app: kafka
  serviceName: kafka-headless
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - command:
        - sh
        - -exc
        - |
          unset KAFKA_PORT &amp;&amp; <br />
          export KAFKA_BROKER_ID=${HOSTNAME##*-} &amp;&amp; <br />
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_IP}:9092 &amp;&amp; <br />
          exec /etc/confluent/docker/run
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: KAFKA_HEAP_OPTS
          value: -Xmx1G -Xms1G
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: zk-cs:2181
        - name: KAFKA_LOG_DIRS
          value: /opt/kafka/data/logs
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: &ldquo;3&rdquo;
        - name: KAFKA_JMX_PORT
          value: &ldquo;5555&rdquo;
        image: confluentinc/cp-kafka:4.1.2-2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - sh
            - -ec
            - /usr/bin/jps | /bin/grep -q SupportedKafka
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: kafka-broker
        ports:
        - containerPort: 9092
          name: kafka
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: kafka
          timeoutSeconds: 5
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /opt/kafka/data
          name: datadir
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 60
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: &ldquo;local-class&rdquo;
      resources:
        requests:
          storage: 1Gi</p>

<pre><code>
查看部署情况
</code></pre>

<p>bash
root@hw1:~/zk# kubectl get pods
NAME                READY   STATUS    RESTARTS   AGE
busybox             <sup>1</sup>&frasl;<sub>1</sub>     Running   20         20h
kafka-0             <sup>1</sup>&frasl;<sub>1</sub>     Running   9          18h
kafka-1             <sup>1</sup>&frasl;<sub>1</sub>     Running   0          18h
kafka-2             <sup>1</sup>&frasl;<sub>1</sub>     Running   0          18h
zk-0                <sup>1</sup>&frasl;<sub>1</sub>     Running   0          18h
zk-1                <sup>1</sup>&frasl;<sub>1</sub>     Running   0          18h
zk-2                <sup>1</sup>&frasl;<sub>1</sub>     Running   0          18h
root@hw1:~/zk# kubectl get pvc
NAME              STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   AGE
datadir-kafka-0   Bound    datadir-kfk-1   5Gi        RWO            local-class    18h
datadir-kafka-1   Bound    datadir-kfk-2   5Gi        RWO            local-class    18h
datadir-kafka-2   Bound    datadir-kfk-3   5Gi        RWO            local-class    18h
datadir-zk-0      Bound    datadir1        5Gi        RWO            local-class    18h
datadir-zk-1      Bound    datadir2        5Gi        RWO            local-class    18h
datadir-zk-2      Bound    datadir3        5Gi        RWO            local-class    18h
root@hw1:~/zk# kubectl get pv
NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   REASON   AGE
datadir-kfk-1   5Gi        RWO            Retain           Bound    default/datadir-kafka-0   local-class             18h
datadir-kfk-2   5Gi        RWO            Retain           Bound    default/datadir-kafka-1   local-class             18h
datadir-kfk-3   5Gi        RWO            Retain           Bound    default/datadir-kafka-2   local-class             18h
datadir1        5Gi        RWO            Retain           Bound    default/datadir-zk-0      local-class             18h
datadir2        5Gi        RWO            Retain           Bound    default/datadir-zk-1      local-class             18h
datadir3        5Gi        RWO            Retain           Bound    default/datadir-zk-2      local-class             18h
root@hw1:~/zk#</p>

<pre><code>
接着，测试kfk是否连接上zk,能够正常的生产消费，同样借用上述老哥的kfk-test-pod，```kubectl create -f pod-test.yaml```。
</code></pre>

<p>yaml
apiVersion: v1
kind: Pod
metadata:
  name: kafka-test-client
spec:
  containers:
  - command:
    - sh
    - -c
    - exec tail -f /dev/null
    image: confluentinc/cp-kafka:4.1.2-2
    imagePullPolicy: IfNotPresent
    name: kafka
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File</p>

<pre><code>
查看topic,并创建test topic。
</code></pre>

<p>bash
root@hw1:~/zk# kubectl exec  kafka-test-client &ndash; /usr/bin/kafka-topics &ndash;zookeeper zk-cs:2181 &ndash;list
__confluent.support.metrics
root@hw1:~/zk# kubectl exec  kafka-test-client &ndash; /usr/bin/kafka-topics &ndash;zookeeper zk-cs:2181 &ndash;topic test &ndash;create &ndash;partitions 1 &ndash;replication-factor 1
Created topic &ldquo;test&rdquo;.</p>

<pre><code>
启动在topic=test的生产者进程，并写入hello world消息。
</code></pre>

<p>bash
root@hw1:~# kubectl exec -it kafka-test-client &ndash;  /usr/bin/kafka-console-producer  &ndash;broker-list kafka:9092 &ndash;topic test
&gt;hello
&gt;world
&gt;</p>

<pre><code>
启动消费者，查看topic=test上的消息。
</code></pre>

<p>bash
root@hw1:~#  kubectl exec  kafka-test-client &ndash; /usr/bin/kafka-console-consumer  &ndash;bootstrap-server kafka:9092 &ndash;topic test &ndash;from-beginning</p>

<p>hello
world
```</p>

<p>至此，zk/kfk都已经部署完成。</p>

<p>参考资料：</p>

<ol>
<li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSets</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/">Storage Classes</a></li>
<li><a href="https://imti.co/kafka-kubernetes/#kafka-service">Kafka on Kubernetes Deploy a highly available Kafka cluster on Kubernetes.</a>
&mdash;</li>
</ol>

<p>接下来，我们要利用zk/kfk集群，部署fabric with kafka consensus。</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
